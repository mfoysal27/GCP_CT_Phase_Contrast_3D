{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df89b43d-0a5c-4553-9bc6-853365e1701e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7a8f7a6c-037f-4b86-a6a8-228e43aa76a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a93b3d99-823b-41b9-922b-48470960f36f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"\n",
    "PROJECT_ID = !(gcloud config get-value project)\n",
    "PROJECT_ID = PROJECT_ID[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "960dba60-235c-4ba7-b948-640f0075e3fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qwiklabs-asl-00-6fcd414e1f60'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5b8701b-df35-4d50-8474-2fdc24103bef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/home/jupyter/.local/bin:/home/jupyter/.local/bin:/home/jupyter/.local/bin:/home/jupyter/.local/bin:/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n"
     ]
    }
   ],
   "source": [
    "# Set `PATH` to include the directory containing KFP CLI\n",
    "PATH = %env PATH\n",
    "%env PATH=/home/jupyter/.local/bin:{PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5034ef2f-4e10-4eff-8320-ad9e0379fda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: jsonschema in /opt/conda/lib/python3.7/site-packages (4.17.3)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.7/site-packages (from jsonschema) (1.3.10)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema) (6.0.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema) (0.19.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from jsonschema) (4.5.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema) (5.12.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema) (22.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources>=1.4.0->jsonschema) (3.15.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install jsonschema\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "52e6229c-6f15-4f59-91ec-27707a993329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nodeenv in /opt/conda/lib/python3.7/site-packages (1.7.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nodeenv) (67.6.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pre-commit in /opt/conda/lib/python3.7/site-packages (2.21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from pre-commit) (5.4.1)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from pre-commit) (1.7.0)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /opt/conda/lib/python3.7/site-packages (from pre-commit) (20.20.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from pre-commit) (3.3.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from pre-commit) (6.0.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from pre-commit) (2.5.22)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nodeenv>=0.11.1->pre-commit) (67.6.0)\n",
      "Requirement already satisfied: platformdirs<4,>=2.4 in /opt/conda/lib/python3.7/site-packages (from virtualenv>=20.10.0->pre-commit) (3.1.0)\n",
      "Requirement already satisfied: filelock<4,>=3.4.1 in /opt/conda/lib/python3.7/site-packages (from virtualenv>=20.10.0->pre-commit) (3.9.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.7/site-packages (from virtualenv>=20.10.0->pre-commit) (0.3.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->pre-commit) (4.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->pre-commit) (3.15.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nodeenv\n",
    "!pip install pre-commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "dc0a0536-5dbf-4248-89f4-615093361352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat trainer_image_vertex/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9989bcbb-8917-4b43-9279-0743045c5456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat trainer_image_vertex/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c7d1a45e-3847-4c1c-ad0f-07c50242d680",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsl-compile\n",
      "dsl-compile-v2\n",
      "kfp\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls /home/jupyter/.local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "228c843c-9f0b-4094-9f4e-9586a1fb39ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c5ef28a2-ec4c-45fd-a9dd-44e300e4946d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/CapStone_Phase_Contrast\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd\n",
    "\n",
    "#cp /home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3e8e9fe0-ba8b-48f9-bcf4-e66fe684086c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/CapStone_Phase_Contrast/trainer_image_vertex'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('trainer_image_vertex')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad19d6-58da-4c9f-8de1-afd27c445660",
   "metadata": {},
   "source": [
    "## name docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1cd9f2bc-d7ea-4753-b05b-12bbed1c41cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/qwiklabs-asl-00-6fcd414e1f60/docker_image_kamrul:latest'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_NAME = \"Dockerfile\"\n",
    "TAG = \"latest\"\n",
    "TRAINING_CONTAINER_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/{IMAGE_NAME}:{TAG}\"\n",
    "TRAINING_CONTAINER_IMAGE_URI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "83da266b-736c-47b4-9e43-6125098b4bf3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-8:latest'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SERVING_CONTAINER_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-8:latest\"\n",
    "SERVING_CONTAINER_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "38245004-3c82-4659-a56e-7eb1c928f222",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7f240aac-a4bd-42ff-8dc1-5e4a49ab9ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/CapStone_Phase_Contrast/trainer_image_vertex'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e28597f5-e663-42c9-89a1-f90ea6921498",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/CapStone_Phase_Contrast/trainer_image_vertex'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/home/jupyter/CapStone_Phase_Contrast/trainer_image_vertex\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a716fe9-44e2-4c91-a538-f492bd1cef7b",
   "metadata": {},
   "source": [
    "## build docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "93ff791a-6d5a-4cbe-8609-04c504ffb3c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 6 file(s) totalling 15.4 KiB before compression.\n",
      "Uploading tarball of [trainer_image_vertex] to [gs://qwiklabs-asl-00-6fcd414e1f60_cloudbuild/source/1680585442.397761-d0a922fbb990474fa48f360ad67072c2.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/qwiklabs-asl-00-6fcd414e1f60/locations/global/builds/cb86c5fb-e430-48ec-b7c5-843f41d0c21a].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/cb86c5fb-e430-48ec-b7c5-843f41d0c21a?project=955332457859 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"cb86c5fb-e430-48ec-b7c5-843f41d0c21a\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://qwiklabs-asl-00-6fcd414e1f60_cloudbuild/source/1680585442.397761-d0a922fbb990474fa48f360ad67072c2.tgz#1680585442675192\n",
      "Copying gs://qwiklabs-asl-00-6fcd414e1f60_cloudbuild/source/1680585442.397761-d0a922fbb990474fa48f360ad67072c2.tgz#1680585442675192...\n",
      "/ [1 files][  3.2 KiB/  3.2 KiB]                                                \n",
      "Operation completed over 1 objects/3.2 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  22.02kB\n",
      "Step 1/6 : FROM gcr.io/deeplearning-platform-release/base-cpu\n",
      "latest: Pulling from deeplearning-platform-release/base-cpu\n",
      "06d39c85623a: Pulling fs layer\n",
      "e7c8f9f1c438: Pulling fs layer\n",
      "efa417d9b60e: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "b7516b3a289c: Pulling fs layer\n",
      "5dbd3ad33a17: Pulling fs layer\n",
      "dd0079218618: Pulling fs layer\n",
      "a04f8bf732fd: Pulling fs layer\n",
      "d2a80a6a8566: Pulling fs layer\n",
      "bb6793638813: Pulling fs layer\n",
      "9c9fa865b021: Pulling fs layer\n",
      "1861303bfb9e: Pulling fs layer\n",
      "0341960adf6d: Pulling fs layer\n",
      "2541824c191a: Pulling fs layer\n",
      "dc8b97e70fb5: Pulling fs layer\n",
      "c0339bfd46d5: Pulling fs layer\n",
      "64e920d3c84c: Pulling fs layer\n",
      "0b85092b6128: Pulling fs layer\n",
      "888d167ffdc1: Pulling fs layer\n",
      "72a1ca3ef675: Pulling fs layer\n",
      "67b47bfff495: Pulling fs layer\n",
      "1860943e77f2: Pulling fs layer\n",
      "82f817bcd783: Pulling fs layer\n",
      "4f4fb700ef54: Waiting\n",
      "b7516b3a289c: Waiting\n",
      "5dbd3ad33a17: Waiting\n",
      "dd0079218618: Waiting\n",
      "a04f8bf732fd: Waiting\n",
      "d2a80a6a8566: Waiting\n",
      "bb6793638813: Waiting\n",
      "9c9fa865b021: Waiting\n",
      "1861303bfb9e: Waiting\n",
      "0341960adf6d: Waiting\n",
      "2541824c191a: Waiting\n",
      "dc8b97e70fb5: Waiting\n",
      "c0339bfd46d5: Waiting\n",
      "64e920d3c84c: Waiting\n",
      "0b85092b6128: Waiting\n",
      "888d167ffdc1: Waiting\n",
      "72a1ca3ef675: Waiting\n",
      "67b47bfff495: Waiting\n",
      "1860943e77f2: Waiting\n",
      "82f817bcd783: Waiting\n",
      "efa417d9b60e: Verifying Checksum\n",
      "efa417d9b60e: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "06d39c85623a: Verifying Checksum\n",
      "06d39c85623a: Download complete\n",
      "e7c8f9f1c438: Verifying Checksum\n",
      "e7c8f9f1c438: Download complete\n",
      "dd0079218618: Verifying Checksum\n",
      "dd0079218618: Download complete\n",
      "a04f8bf732fd: Verifying Checksum\n",
      "a04f8bf732fd: Download complete\n",
      "d2a80a6a8566: Download complete\n",
      "5dbd3ad33a17: Verifying Checksum\n",
      "5dbd3ad33a17: Download complete\n",
      "9c9fa865b021: Verifying Checksum\n",
      "9c9fa865b021: Download complete\n",
      "1861303bfb9e: Verifying Checksum\n",
      "1861303bfb9e: Download complete\n",
      "0341960adf6d: Verifying Checksum\n",
      "0341960adf6d: Download complete\n",
      "2541824c191a: Verifying Checksum\n",
      "2541824c191a: Download complete\n",
      "bb6793638813: Verifying Checksum\n",
      "bb6793638813: Download complete\n",
      "b7516b3a289c: Verifying Checksum\n",
      "b7516b3a289c: Download complete\n",
      "dc8b97e70fb5: Download complete\n",
      "c0339bfd46d5: Verifying Checksum\n",
      "c0339bfd46d5: Download complete\n",
      "64e920d3c84c: Verifying Checksum\n",
      "64e920d3c84c: Download complete\n",
      "888d167ffdc1: Verifying Checksum\n",
      "888d167ffdc1: Download complete\n",
      "0b85092b6128: Verifying Checksum\n",
      "0b85092b6128: Download complete\n",
      "72a1ca3ef675: Verifying Checksum\n",
      "72a1ca3ef675: Download complete\n",
      "67b47bfff495: Verifying Checksum\n",
      "67b47bfff495: Download complete\n",
      "82f817bcd783: Verifying Checksum\n",
      "82f817bcd783: Download complete\n",
      "06d39c85623a: Pull complete\n",
      "e7c8f9f1c438: Pull complete\n",
      "efa417d9b60e: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "1860943e77f2: Verifying Checksum\n",
      "1860943e77f2: Download complete\n",
      "b7516b3a289c: Pull complete\n",
      "5dbd3ad33a17: Pull complete\n",
      "dd0079218618: Pull complete\n",
      "a04f8bf732fd: Pull complete\n",
      "d2a80a6a8566: Pull complete\n",
      "bb6793638813: Pull complete\n",
      "9c9fa865b021: Pull complete\n",
      "1861303bfb9e: Pull complete\n",
      "0341960adf6d: Pull complete\n",
      "2541824c191a: Pull complete\n",
      "dc8b97e70fb5: Pull complete\n",
      "c0339bfd46d5: Pull complete\n",
      "64e920d3c84c: Pull complete\n",
      "0b85092b6128: Pull complete\n",
      "888d167ffdc1: Pull complete\n",
      "72a1ca3ef675: Pull complete\n",
      "67b47bfff495: Pull complete\n",
      "1860943e77f2: Pull complete\n",
      "82f817bcd783: Pull complete\n",
      "Digest: sha256:914ba5bc4fd8f663f460a704f7902e90e86fac154d9f3138ee380bc74f85a609\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/base-cpu:latest\n",
      " ---> cc816c6878af\n",
      "Step 2/6 : RUN pip install -U cloudml-hypertune  pandas==0.24.2\n",
      " ---> Running in 8cbfb874ba22\n",
      "Collecting cloudml-hypertune\n",
      "  Downloading cloudml-hypertune-0.1.0.dev6.tar.gz (3.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pandas==0.24.2\n",
      "  Downloading pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.1/10.1 MB 53.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from pandas==0.24.2) (1.21.6)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.7/site-packages (from pandas==0.24.2) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from pandas==0.24.2) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas==0.24.2) (1.16.0)\n",
      "Building wheels for collected packages: cloudml-hypertune\n",
      "  Building wheel for cloudml-hypertune (setup.py): started\n",
      "  Building wheel for cloudml-hypertune (setup.py): finished with status 'done'\n",
      "  Created wheel for cloudml-hypertune: filename=cloudml_hypertune-0.1.0.dev6-py2.py3-none-any.whl size=3973 sha256=13f9bbea4e899d4e4921748b35e31ae7dfd730f72da250d53996cfbea2fc50cb\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/ff/87/e7bed0c2741fe219b3d6da67c2431d7f7fedb183032e00f81e\n",
      "Successfully built cloudml-hypertune\n",
      "Installing collected packages: cloudml-hypertune, pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.5\n",
      "    Uninstalling pandas-1.3.5:\n",
      "      Successfully uninstalled pandas-1.3.5\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ydata-profiling 4.1.2 requires pandas!=1.4.0,<1.6,>1.1, but you have pandas 0.24.2 which is incompatible.\n",
      "visions 0.7.5 requires pandas>=0.25.3, but you have pandas 0.24.2 which is incompatible.\n",
      "statsmodels 0.13.5 requires pandas>=0.25, but you have pandas 0.24.2 which is incompatible.\n",
      "seaborn 0.12.2 requires pandas>=0.25, but you have pandas 0.24.2 which is incompatible.\n",
      "phik 0.12.3 requires pandas>=0.25.1, but you have pandas 0.24.2 which is incompatible.\n",
      "\u001b[0mSuccessfully installed cloudml-hypertune-0.1.0.dev6 pandas-0.24.2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 8cbfb874ba22\n",
      " ---> 71d9782a6a7f\n",
      "Step 3/6 : WORKDIR /app\n",
      " ---> Running in f40499b10c55\n",
      "Removing intermediate container f40499b10c55\n",
      " ---> d2aa84aed81f\n",
      "Step 4/6 : COPY model.py .\n",
      " ---> c04daf3478f8\n",
      "Step 5/6 : COPY task.py .\n",
      " ---> 3556b6eda479\n",
      "Step 6/6 : ENTRYPOINT [\"python\", \"task.py\"]\n",
      " ---> Running in 59501a336b27\n",
      "Removing intermediate container 59501a336b27\n",
      " ---> 5b73c6a04718\n",
      "Successfully built 5b73c6a04718\n",
      "Successfully tagged gcr.io/qwiklabs-asl-00-6fcd414e1f60/docker_image_kamrul:latest\n",
      "PUSH\n",
      "Pushing gcr.io/qwiklabs-asl-00-6fcd414e1f60/docker_image_kamrul:latest\n",
      "The push refers to repository [gcr.io/qwiklabs-asl-00-6fcd414e1f60/docker_image_kamrul]\n",
      "bf5afbaf114e: Preparing\n",
      "769cd803534c: Preparing\n",
      "6677a6287699: Preparing\n",
      "ec07e2e49fe0: Preparing\n",
      "5c673b8f934f: Preparing\n",
      "c02dcf5e3110: Preparing\n",
      "52f2c44dd7d5: Preparing\n",
      "1a8787181ec0: Preparing\n",
      "ed8683b9a009: Preparing\n",
      "43aeb7c225e9: Preparing\n",
      "4a85034bc747: Preparing\n",
      "a989b70dea57: Preparing\n",
      "26be33be3bda: Preparing\n",
      "0feb37ecf603: Preparing\n",
      "949b9cfe3ff6: Preparing\n",
      "4a94e97b0bad: Preparing\n",
      "c6ed382fffa0: Preparing\n",
      "0ff27ed66c67: Preparing\n",
      "9769a380e7be: Preparing\n",
      "4dc2f517c0c7: Preparing\n",
      "3986a28bd658: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "99e019e31aa2: Preparing\n",
      "7132efbd60b5: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "8b277e208e0b: Preparing\n",
      "0159e6b32683: Preparing\n",
      "62789ffcd78c: Preparing\n",
      "c02dcf5e3110: Waiting\n",
      "52f2c44dd7d5: Waiting\n",
      "1a8787181ec0: Waiting\n",
      "ed8683b9a009: Waiting\n",
      "43aeb7c225e9: Waiting\n",
      "a989b70dea57: Waiting\n",
      "26be33be3bda: Waiting\n",
      "0feb37ecf603: Waiting\n",
      "949b9cfe3ff6: Waiting\n",
      "4a94e97b0bad: Waiting\n",
      "c6ed382fffa0: Waiting\n",
      "0ff27ed66c67: Waiting\n",
      "9769a380e7be: Waiting\n",
      "4dc2f517c0c7: Waiting\n",
      "3986a28bd658: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "99e019e31aa2: Waiting\n",
      "7132efbd60b5: Waiting\n",
      "8b277e208e0b: Waiting\n",
      "0159e6b32683: Waiting\n",
      "62789ffcd78c: Waiting\n",
      "4a85034bc747: Waiting\n",
      "5c673b8f934f: Layer already exists\n",
      "c02dcf5e3110: Layer already exists\n",
      "52f2c44dd7d5: Layer already exists\n",
      "1a8787181ec0: Layer already exists\n",
      "ed8683b9a009: Layer already exists\n",
      "43aeb7c225e9: Layer already exists\n",
      "4a85034bc747: Layer already exists\n",
      "a989b70dea57: Layer already exists\n",
      "26be33be3bda: Layer already exists\n",
      "0feb37ecf603: Layer already exists\n",
      "949b9cfe3ff6: Layer already exists\n",
      "4a94e97b0bad: Layer already exists\n",
      "c6ed382fffa0: Layer already exists\n",
      "0ff27ed66c67: Layer already exists\n",
      "9769a380e7be: Layer already exists\n",
      "4dc2f517c0c7: Layer already exists\n",
      "3986a28bd658: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "99e019e31aa2: Layer already exists\n",
      "7132efbd60b5: Layer already exists\n",
      "8b277e208e0b: Layer already exists\n",
      "0159e6b32683: Layer already exists\n",
      "62789ffcd78c: Layer already exists\n",
      "6677a6287699: Pushed\n",
      "769cd803534c: Pushed\n",
      "bf5afbaf114e: Pushed\n",
      "ec07e2e49fe0: Pushed\n",
      "latest: digest: sha256:1d07071aae09b5312396d85bc1b2580ad029dcfe9f24e617a6494f3814595d0e size: 6169\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                             STATUS\n",
      "cb86c5fb-e430-48ec-b7c5-843f41d0c21a  2023-04-04T05:17:22+00:00  2M14S     gs://qwiklabs-asl-00-6fcd414e1f60_cloudbuild/source/1680585442.397761-d0a922fbb990474fa48f360ad67072c2.tgz  gcr.io/qwiklabs-asl-00-6fcd414e1f60/docker_image_kamrul (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --timeout 15m --tag $TRAINING_CONTAINER_IMAGE_URI trainer_image_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd55b7-dab3-4d21-9978-c7170e6737d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e57430e2-2c28-4cbb-b524-49f188874d54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### setup environment variables for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "094d3188-092f-4b7c-874f-2c8d78408cdf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PIPELINE_ROOT=gs://qwiklabs-asl-00-6fcd414e1f60-kfp-artifact-store/pipeline\n",
      "env: PROJECT_ID=qwiklabs-asl-00-6fcd414e1f60\n",
      "env: REGION=us-central1\n",
      "env: SERVING_CONTAINER_IMAGE_URI=us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-8:latest\n",
      "env: TRAINING_CONTAINER_IMAGE_URI=gcr.io/qwiklabs-asl-00-6fcd414e1f60/docker_image_kamrul:latest\n",
      "env: TRAINING_FILE_PATH=gs://qwiklabs-asl-00-6fcd414e1f60-kfp-artifact-store/data/training/dataset.csv\n",
      "env: VALIDATION_FILE_PATH=gs://qwiklabs-asl-00-6fcd414e1f60-kfp-artifact-store/data/validation/dataset.csv\n",
      "env: BASE_OUTPUT_DIR=gs://qwiklabs-asl-00-6fcd414e1f60-kfp-artifact-store/models/20230404060703\n",
      "env: MAX_TRIAL_COUNT=1\n"
     ]
    }
   ],
   "source": [
    "ARTIFACT_STORE = f\"gs://{PROJECT_ID}-kfp-artifact-store\"\n",
    "PIPELINE_ROOT = f\"{ARTIFACT_STORE}/pipeline\"\n",
    "DATA_ROOT = f\"{ARTIFACT_STORE}/data\"\n",
    "\n",
    "TRAINING_FILE_PATH = f\"{DATA_ROOT}/training/dataset.csv\"\n",
    "VALIDATION_FILE_PATH = f\"{DATA_ROOT}/validation/dataset.csv\"\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BASE_OUTPUT_DIR = f\"{ARTIFACT_STORE}/models/{TIMESTAMP}\"\n",
    "\n",
    "%env PIPELINE_ROOT={PIPELINE_ROOT}\n",
    "%env PROJECT_ID={PROJECT_ID}\n",
    "%env REGION={REGION}\n",
    "%env SERVING_CONTAINER_IMAGE_URI={SERVING_CONTAINER_IMAGE_URI}\n",
    "%env TRAINING_CONTAINER_IMAGE_URI={TRAINING_CONTAINER_IMAGE_URI}\n",
    "%env TRAINING_FILE_PATH={TRAINING_FILE_PATH}\n",
    "%env VALIDATION_FILE_PATH={VALIDATION_FILE_PATH}\n",
    "%env BASE_OUTPUT_DIR={BASE_OUTPUT_DIR}\n",
    "%env MAX_TRIAL_COUNT={1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f539cc3-15b7-4de6-98a1-d784bad42912",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let us make sure that the `ARTIFACT_STORE` has been created, and let us create it if not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "88565388-e96e-4916-a9f0-38ab42433ccc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-asl-00-6fcd414e1f60-kfp-artifact-store/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls | grep ^{ARTIFACT_STORE}/$ || gsutil mb -l {REGION} {ARTIFACT_STORE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6127e7b9-11e3-4ba6-a998-363fd3c3ac68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-asl-00-6fcd414e1f60-kfp-artifact-store/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!gsutil ls | grep ^{ARTIFACT_STORE}/$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297d159-50af-494d-bcb2-a707c98374be",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Use the CLI compiler to compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "22b9ca9c-8322-4dcf-af68-b1f2c78f4eb3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# PIPELINE_JSON = \"kamrul_kfp_pipeline.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1872de4b-d745-4504-a5df-2ad4a9796b88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2021 Google LLC\n",
      "\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n",
      "# use this file except in compliance with the License. You may obtain a copy of\n",
      "# the License at\n",
      "\n",
      "# https://www.apache.org/licenses/LICENSE-2.0\n",
      "\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\"\n",
      "# BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
      "# express or implied. See the License for the specific language governing\n",
      "# permissions and limitations under the License.\n",
      "\"\"\"Kubeflow Covertype Pipeline.\"\"\"\n",
      "import os\n",
      "\n",
      "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
      "from google_cloud_pipeline_components.aiplatform import (\n",
      "    EndpointCreateOp,\n",
      "    ModelDeployOp,\n",
      "    ModelUploadOp,\n",
      ")\n",
      "from google_cloud_pipeline_components.experimental import (\n",
      "    hyperparameter_tuning_job,\n",
      ")\n",
      "from google_cloud_pipeline_components.experimental.custom_job import (\n",
      "    CustomTrainingJobOp,\n",
      ")\n",
      "from kfp.v2 import dsl\n",
      "\n",
      "PIPELINE_ROOT = os.getenv(\"PIPELINE_ROOT\")\n",
      "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
      "REGION = os.getenv(\"REGION\")\n",
      "\n",
      "TRAINING_CONTAINER_IMAGE_URI = os.getenv(\"TRAINING_CONTAINER_IMAGE_URI\")\n",
      "SERVING_CONTAINER_IMAGE_URI = os.getenv(\"SERVING_CONTAINER_IMAGE_URI\")\n",
      "SERVING_MACHINE_TYPE = os.getenv(\"SERVING_MACHINE_TYPE\", \"n1-standard-16\")\n",
      "\n",
      "TRAINING_FILE_PATH = os.getenv(\"TRAINING_FILE_PATH\")\n",
      "VALIDATION_FILE_PATH = os.getenv(\"VALIDATION_FILE_PATH\")\n",
      "\n",
      "MAX_TRIAL_COUNT = int(os.getenv(\"MAX_TRIAL_COUNT\", \"1\"))\n",
      "PARALLEL_TRIAL_COUNT = int(os.getenv(\"PARALLEL_TRIAL_COUNT\", \"1\"))\n",
      "THRESHOLD = float(os.getenv(\"THRESHOLD\", \"0.6\"))\n",
      "\n",
      "PIPELINE_NAME = os.getenv(\"PIPELINE_NAME\", \"ct-phase-contrast\")\n",
      "BASE_OUTPUT_DIR = os.getenv(\"BASE_OUTPUT_DIR\", PIPELINE_ROOT)\n",
      "MODEL_DISPLAY_NAME = os.getenv(\"MODEL_DISPLAY_NAME\", PIPELINE_NAME)\n",
      "\n",
      "\n",
      "@dsl.pipeline(\n",
      "    name=f\"{PIPELINE_NAME}-kfp-pipeline\",\n",
      "    description=\"Kubeflow pipeline that tunes, trains, and deploys on Vertex\",\n",
      "    pipeline_root=PIPELINE_ROOT,\n",
      ")\n",
      "def create_pipeline():\n",
      "\n",
      "    worker_pool_specs = [\n",
      "        {\n",
      "            \"machine_spec\": {\n",
      "                \"machine_type\": \"n1-highmem-16\",\n",
      "                \"accelerator_type\": \"NVIDIA_TESLA_P100\",\n",
      "                \"accelerator_count\": 2,\n",
      "            },\n",
      "            \"replica_count\": 1,\n",
      "            \"container_spec\": {\n",
      "                \"image_uri\": TRAINING_CONTAINER_IMAGE_URI,\n",
      "                \"args\": [\n",
      "                    f\"--train_data_path={TRAINING_FILE_PATH}\",\n",
      "                    f\"--eval_data_path={VALIDATION_FILE_PATH}\",\n",
      "                    f\"--output_dir={BASE_OUTPUT_DIR}\",\n",
      "                    \"--hptune\",\n",
      "                ],\n",
      "            },\n",
      "        }\n",
      "    ]\n",
      "\n",
      "    metric_spec = hyperparameter_tuning_job.serialize_metrics(\n",
      "        {\"final_val_accuracy\": \"maximize\"}\n",
      "    )\n",
      "\n",
      "    parameter_spec = hyperparameter_tuning_job.serialize_parameters(\n",
      "        {\n",
      "            \"dropout_rate\": hpt.DoubleParameterSpec(\n",
      "                min=1.0e-3, max=4.0e-1, scale=\"log\"\n",
      "            ),\n",
      "            \"l2_regularization_lambda\": hpt.DoubleParameterSpec(\n",
      "                min=1.0e-3, max=4.0e-1, scale=\"log\"\n",
      "            ),\n",
      "        }\n",
      "    )\n",
      "\n",
      "    hp_tuning_task = hyperparameter_tuning_job.HyperparameterTuningJobRunOp(\n",
      "        display_name=f\"{PIPELINE_NAME}-kfp-tuning-job\",\n",
      "        project=PROJECT_ID,\n",
      "        location=REGION,\n",
      "        worker_pool_specs=worker_pool_specs,\n",
      "        study_spec_metrics=metric_spec,\n",
      "        study_spec_parameters=parameter_spec,\n",
      "        max_trial_count=MAX_TRIAL_COUNT,\n",
      "        parallel_trial_count=PARALLEL_TRIAL_COUNT,\n",
      "        base_output_directory=PIPELINE_ROOT,\n",
      "    )\n",
      "\n",
      "    trials_task = hyperparameter_tuning_job.GetTrialsOp(\n",
      "        gcp_resources=hp_tuning_task.outputs[\"gcp_resources\"]\n",
      "    )\n",
      "\n",
      "    best_hyperparameters_task = (\n",
      "        hyperparameter_tuning_job.GetBestHyperparametersOp(\n",
      "            trials=trials_task.output, study_spec_metrics=metric_spec\n",
      "        )\n",
      "    )\n",
      "\n",
      "    # Construct new worker_pool_specs and\n",
      "    # train new model based on best hyperparameters\n",
      "    worker_pool_specs_task = hyperparameter_tuning_job.GetWorkerPoolSpecsOp(\n",
      "        best_hyperparameters=best_hyperparameters_task.output,\n",
      "        worker_pool_specs=[\n",
      "            {\n",
      "                \"machine_spec\": {\"machine_type\": \"n1-highmem-16\",\n",
      "                                 \"accelerator_type\": \"NVIDIA_TESLA_P100\",\n",
      "                                 \"accelerator_count\": 2},\n",
      "                \"replica_count\": 1,\n",
      "                \"container_spec\": {\n",
      "                    \"image_uri\": TRAINING_CONTAINER_IMAGE_URI,\n",
      "                    \"args\": [\n",
      "                        f\"--train_data_path={TRAINING_FILE_PATH}\",\n",
      "                        f\"--eval_data_path={VALIDATION_FILE_PATH}\",\n",
      "                        f\"--output_dir={BASE_OUTPUT_DIR}\",\n",
      "                    ],\n",
      "                },\n",
      "            }\n",
      "        ],\n",
      "    )\n",
      "\n",
      "    training_task = CustomTrainingJobOp(\n",
      "        project=PROJECT_ID,\n",
      "        location=REGION,\n",
      "        display_name=f\"{PIPELINE_NAME}-kfp-training-job\",\n",
      "        worker_pool_specs=worker_pool_specs_task.output,\n",
      "        base_output_directory=BASE_OUTPUT_DIR,\n",
      "    )\n",
      "\n",
      "    model_upload_task = ModelUploadOp(\n",
      "        project=PROJECT_ID,\n",
      "        display_name=f\"{PIPELINE_NAME}-kfp-model-upload-job\",\n",
      "        artifact_uri=f\"{BASE_OUTPUT_DIR}/model\",\n",
      "        serving_container_image_uri=SERVING_CONTAINER_IMAGE_URI,\n",
      "    )\n",
      "    model_upload_task.after(training_task)\n",
      "\n",
      "    endpoint_create_task = EndpointCreateOp(\n",
      "        project=PROJECT_ID,\n",
      "        display_name=f\"{PIPELINE_NAME}-kfp-create-endpoint-job\",\n",
      "    )\n",
      "    endpoint_create_task.after(model_upload_task)\n",
      "\n",
      "    model_deploy_op = ModelDeployOp(  # pylint: disable=unused-variable\n",
      "        model=model_upload_task.outputs[\"model\"],\n",
      "        endpoint=endpoint_create_task.outputs[\"endpoint\"],\n",
      "        deployed_model_display_name=MODEL_DISPLAY_NAME,\n",
      "        dedicated_resources_machine_type=SERVING_MACHINE_TYPE,\n",
      "        dedicated_resources_min_replica_count=1,\n",
      "        dedicated_resources_max_replica_count=1,\n",
      "    )\n"
     ]
    }
   ],
   "source": [
    "!cat pipeline_vertex/pipeline_prebuilt.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "80973f08-7c02-483f-a9c7-ab98c63a7c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_JSON = \"ct_contrast_kfp_pipeline.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "28128ec5-fc4d-404e-a493-11409cf188d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1293: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "!dsl-compile-v2 --py pipeline_vertex/pipeline_prebuilt.py --output $PIPELINE_JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "235c8126-6547-42f2-a0e2-b4eb699c767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"pipelineSpec\": {\n",
      "    \"components\": {\n",
      "      \"comp-custom-training-job\": {\n",
      "        \"executorLabel\": \"exec-custom-training-job\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"base_output_directory\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n"
     ]
    }
   ],
   "source": [
    "!head {PIPELINE_JSON}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb5309-1c39-4cb3-b514-cdab37a4f95a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ca220f52-e6e4-432b-8daf-c8a98b08f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from kfp.v2 import compiler\n",
    "\n",
    "# compiler.Compiler().compile(\n",
    "#     pipeline_func=create_pipeline, \n",
    "#     package_path=PIPELINE_JSON,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36848a6a-a20c-4611-9460-857dbd649fc3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Note:** You can also use the Python SDK to compile the pipeline:\n",
    "\n",
    "```python\n",
    "from kfp.v2 import compiler\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=create_pipeline, \n",
    "    package_path=PIPELINE_JSON,\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e5818711-6a27-40a3-8d2a-59b561e984ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"pipelineSpec\": {\n",
      "    \"components\": {\n",
      "      \"comp-custom-training-job\": {\n",
      "        \"executorLabel\": \"exec-custom-training-job\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"base_output_directory\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n"
     ]
    }
   ],
   "source": [
    "!head {PIPELINE_JSON}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4158eca6-9bab-4ff4-b959-39674d54820c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Deploy the pipeline package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "80af2fc7-c2a6-4e5b-b516-856e29085b5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/955332457859/locations/us-central1/pipelineJobs/ct-phase-contrast-kfp-pipeline-20230405160213\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/955332457859/locations/us-central1/pipelineJobs/ct-phase-contrast-kfp-pipeline-20230405160213')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/ct-phase-contrast-kfp-pipeline-20230405160213?project=955332457859\n",
      "PipelineJob projects/955332457859/locations/us-central1/pipelineJobs/ct-phase-contrast-kfp-pipeline-20230405160213 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/955332457859/locations/us-central1/pipelineJobs/ct-phase-contrast-kfp-pipeline-20230405160213 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/955332457859/locations/us-central1/pipelineJobs/ct-phase-contrast-kfp-pipeline-20230405160213 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/955332457859/locations/us-central1/pipelineJobs/ct-phase-contrast-kfp-pipeline-20230405160213 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/955332457859/locations/us-central1/pipelineJobs/ct-phase-contrast-kfp-pipeline-20230405160213 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/955332457859/locations/us-central1/pipelineJobs/ct-phase-contrast-kfp-pipeline-20230405160213 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/955332457859/locations/us-central1/pipelineJobs/ct-phase-contrast-kfp-pipeline-20230405160213 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [hyperparameter-tuning-job].; Job (project_id = qwiklabs-asl-00-6fcd414e1f60, job_id = 4479951881036103680) is failed due to the above error.; Failed to handle the job: {project_number = 955332457859, job_id = 4479951881036103680}\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_1994/1993467995.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mnetwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mcreate_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, service_account, network, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    349\u001b[0m         )\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     def submit(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_PIPELINE_ERROR_STATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job failed with:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_action_completed_against_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [hyperparameter-tuning-job].; Job (project_id = qwiklabs-asl-00-6fcd414e1f60, job_id = 4479951881036103680) is failed due to the above error.; Failed to handle the job: {project_number = 955332457859, job_id = 4479951881036103680}\"\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "pipeline = aiplatform.PipelineJob(\n",
    "    display_name=\"ct_contrast_kfp_pipeline\",\n",
    "    template_path=PIPELINE_JSON,\n",
    "    enable_caching=True,\n",
    ")\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcd2b46-5bb0-4a0f-8558-e1f8c1773a29",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m104"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
